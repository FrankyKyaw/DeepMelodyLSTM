{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b4efb1-d168-4aa7-9178-115202ad19fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 12:49:03.109629: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 12:49:03.174917: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-01 12:49:03.461548: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jupyter-franky/.conda/envs/tf/lib/\n",
      "2024-05-01 12:49:03.461577: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jupyter-franky/.conda/envs/tf/lib/\n",
      "2024-05-01 12:49:03.461579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from music21 import converter, instrument, stream, roman, midi, key, interval\n",
    "import music21\n",
    "import music21.chord as chord_module\n",
    "import music21.note as note_module\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, Embedding, Concatenate, Input, Bidirectional, Attention\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd87a18-935c-4920-a514-9377e5cda593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 12:49:04.453881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-01 12:49:04.456569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-01 12:49:04.456630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a7ef38-0879-44da-9636-ce1aa8fdbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataset/pop_909/*.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2524825-d339-48c9-ae88-d360aa3b4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_mapping = {\n",
    "    0.25: 0,  # Sixteenth note\n",
    "    0.5: 1,   # Eighth note\n",
    "    0.75: 2,\n",
    "    1.0: 3,   # Quarter note\n",
    "    1.25: 4,\n",
    "    1.5: 5,   # Dotted quarter note\n",
    "    1.75: 6,\n",
    "    2.0: 7,   # Half note\n",
    "    2.25: 8,\n",
    "    2.5: 9,   \n",
    "    2.75: 10,\n",
    "    3.0: 11,   \n",
    "    3.25: 12,  \n",
    "    3.5: 13,   \n",
    "    3.75: 14, \n",
    "    4.0: 15    # Whole note\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e67ae5e-e12b-47ae-b74e-565c6f822f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(duration, duration_mapping=duration_mapping):\n",
    "    min_diff = float('inf')\n",
    "    nearest_duration = None\n",
    "    for key in duration_mapping:\n",
    "        diff = abs(duration - key)\n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            nearest_duration = key\n",
    "    return duration_mapping[nearest_duration]\n",
    "\n",
    "\n",
    "def simplify_roman_name(roman_numeral):\n",
    "    \"\"\"\n",
    "    Simplify roman numeral chord names.\n",
    "    \"\"\"\n",
    "    chord_name = roman_numeral.figure\n",
    "    # Match everything up to the first digit\n",
    "    match = re.match(r\"^[^\\d]*\\d\", chord_name)\n",
    "    if match:\n",
    "        simplified_name = match.group(0) \n",
    "    else:\n",
    "        simplified_name = chord_name\n",
    "    return simplified_name\n",
    " \n",
    "def extract_chords(stream, transposed_key):\n",
    "    all_chords = []\n",
    "    for measure in stream.measures(numberStart=0, numberEnd=None):\n",
    "        note_durations = {}\n",
    "        for element in measure.notesAndRests:\n",
    "            if isinstance(element, chord_module.Chord):\n",
    "                for single_note in element.pitches:\n",
    "                    midi_value = single_note.midi\n",
    "                    duration = get_duration(float(element.duration.quarterLength), duration_mapping)\n",
    "                    note_durations[midi_value] = duration\n",
    "            elif isinstance(element, note_module.Note):\n",
    "                midi_value = element.pitch.midi\n",
    "                duration = get_duration(float(element.duration.quarterLength), duration_mapping)\n",
    "                note_durations[midi_value] = duration\n",
    "            elif isinstance(element, note_module.Rest):\n",
    "                continue\n",
    "        \n",
    "        simplified_name = 'rest_or_no_chord'\n",
    "        if note_durations:\n",
    "            sorted_notes = sorted(note_durations, key=note_durations.get, reverse=True)\n",
    "            if len(sorted_notes) >= 2:\n",
    "                freq = chord_module.Chord(sorted_notes[:4])\n",
    "                rn = roman.romanNumeralFromChord(freq, transposed_key)\n",
    "                simplified_name = simplify_roman_name(rn)\n",
    "        for _ in range(4):\n",
    "            all_chords.append([simplified_name])\n",
    "    return all_chords\n",
    "\n",
    "\n",
    "def extract_notes(stream, duration_mapping=duration_mapping):\n",
    "    all_notes = []\n",
    "    all_durations = []\n",
    "    for measure in stream.measures(numberStart=0, numberEnd=None):\n",
    "        measure_notes = {}\n",
    "        \n",
    "        for element in measure.notesAndRests:\n",
    "            beat = element.beat\n",
    "            if beat not in measure_notes:\n",
    "                measure_notes[beat] = []\n",
    "            measure_notes[beat].append(element)\n",
    "        for beat, notes in measure_notes.items():\n",
    "            beat_notes = []\n",
    "            beat_durations = []\n",
    "            for note in notes:\n",
    "                if isinstance(note, note_module.Note):\n",
    "                    midi_value = note.pitch.midi\n",
    "                    duration = get_duration(float(note.duration.quarterLength), duration_mapping)\n",
    "                    beat_notes.append(midi_value)\n",
    "                    beat_durations.append(duration)\n",
    "                elif isinstance(note, note_module.Rest):\n",
    "                    duration = get_duration(float(note.duration.quarterLength), duration_mapping)\n",
    "                    beat_notes.append('R')\n",
    "                    beat_durations.append(duration)\n",
    "                else:\n",
    "                    beat_notes.append('R')\n",
    "                    beat_durations.append(0)\n",
    "            all_notes.append(beat_notes)\n",
    "            all_durations.append(beat_durations)\n",
    "    return all_notes, all_durations\n",
    "\n",
    "def add_padding(notes_list, target_length):\n",
    "    if len(notes_list) < target_length:\n",
    "        pad_length = target_length - len(notes_list)\n",
    "        notes_list.extend(['<padding>' for _ in range(pad_length)])\n",
    "    return notes_list\n",
    "\n",
    "def extract_parts(file_path):\n",
    "    try:\n",
    "        midi = converter.parse(file_path)\n",
    "        original_key = midi.analyze('key')\n",
    "        transposed_key = original_key\n",
    "        # if str(original_key) != 'C major' or str(original_key) != 'a minor':\n",
    "        #     transposed_key = key.Key('C')\n",
    "        #     note_interval = interval.Interval(original_key.tonic, transposed_key.tonic)\n",
    "        #     midi = midi.transpose(note_interval)\n",
    "        # else:\n",
    "        #     transposed_key = original_key\n",
    "            \n",
    "        melody_stream = stream.Stream()\n",
    "        bridge_stream = stream.Stream()\n",
    "        piano_stream = stream.Stream()\n",
    "\n",
    "        for part in midi.parts:\n",
    "            if part.partName == 'MELODY':\n",
    "                melody_stream = part\n",
    "            elif part.partName == 'BRIDGE':\n",
    "                bridge_stream = part\n",
    "            elif part.partName == 'PIANO':\n",
    "                piano_stream = part\n",
    "\n",
    "        all_notes, all_durations = extract_notes(melody_stream)\n",
    "        # bridge_notes = extract_notes(bridge_stream)\n",
    "        all_chords = extract_chords(piano_stream, transposed_key)\n",
    "\n",
    "        max_length = max(len(all_notes), len(all_chords), len(all_durations))\n",
    "        all_notes = add_padding(all_notes, max_length)\n",
    "        all_durations = add_padding(all_durations, max_length)\n",
    "        # bridge_notes = pad_or_truncate(bridge_notes, max_length)\n",
    "        all_chords = add_padding(all_chords, max_length)\n",
    "        \n",
    "        all_notes.append('<end>')\n",
    "        all_durations.append('<end>')\n",
    "        all_chords.append('<end>')\n",
    "        return all_notes, all_durations, all_chords\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {file_path}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74251565-84e2-48d9-8248-b989da2c77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sequences(notes, durations, chords, sequence_length, notes_mapping, chords_mapping, duration_mapping):\n",
    "    encoded_notes = []\n",
    "    encoded_durations = []\n",
    "    for i, note_list in enumerate(notes):\n",
    "        if isinstance(note_list, list) and note_list:\n",
    "            note_str = str(note_list)\n",
    "            encoded_note = notes_mapping.get(str(note_list), -1)\n",
    "            note = note_list[0]\n",
    "            encoded_notes.append(encoded_note)\n",
    "            encoded_durations.append(durations[i][0])\n",
    "        elif isinstance(note_list, str) and note_list in ['<padding>', '<end>']:\n",
    "            encoded_note = notes_mapping.get(note_list, -1)\n",
    "            encoded_notes.append(encoded_note)\n",
    "            encoded_durations.append(0)\n",
    "        else:\n",
    "            encoded_notes.append(notes_mapping.get('<padding>', -1))\n",
    "            encoded_durations.append(0)\n",
    "            \n",
    "    encoded_chords = convert_to_int(chords, chords_mapping)\n",
    "    print(len(encoded_notes), len(encoded_chords))\n",
    "    \n",
    "    network_input_notes = []\n",
    "    network_input_durations = []\n",
    "    network_input_chords = []\n",
    "    network_output_notes = []\n",
    "    network_output_durations = []\n",
    "    network_output_chords = []\n",
    "\n",
    "    # Duplicate each chord 4 times\n",
    "    # encoded_chords_duplicated = [chord for chord in encoded_chords for _ in range(4)]\n",
    "    print(encoded_notes[:20])\n",
    "    print(encoded_durations[:20])\n",
    "    print(encoded_chords[:20])\n",
    "    for i in range(len(encoded_chords) - sequence_length):\n",
    "        sequence_in_notes = encoded_notes[i:i + sequence_length]\n",
    "        sequence_out_note = encoded_notes[i + sequence_length]\n",
    "        sequence_in_durations = encoded_durations[i:i + sequence_length]\n",
    "        sequence_out_duration = encoded_durations[i + sequence_length]\n",
    "        sequence_in_chords = encoded_chords[i:i + sequence_length]\n",
    "        sequence_out_chord = encoded_chords[i + sequence_length]\n",
    "\n",
    "        network_input_notes.append(sequence_in_notes)\n",
    "        network_input_durations.append(sequence_in_durations)\n",
    "        network_input_chords.append(sequence_in_chords)\n",
    "        network_output_notes.append(sequence_out_note)\n",
    "        network_output_durations.append(sequence_out_duration)\n",
    "        network_output_chords.append(sequence_out_chord)\n",
    "\n",
    "    n_vocab_notes = len(set(encoded_notes))\n",
    "    n_vocab_chords = len(set(encoded_chords))\n",
    "    n_vocab_durations = len(duration_mapping)\n",
    "    \n",
    "    return np.array(network_input_notes), np.array(network_input_durations), np.array(network_input_chords), np.array(network_output_notes), np.array(network_output_durations), np.array(network_output_chords), n_vocab_notes, n_vocab_chords, n_vocab_durations\n",
    "    \n",
    "def create_mappings(items_list, file_path):\n",
    "    unique_items = []\n",
    "    for item in items_list:\n",
    "        if isinstance(item, tuple):\n",
    "            note, duration = item\n",
    "        else:\n",
    "            note = item\n",
    "        unique_items.append(str(note))\n",
    "        \n",
    "    unique_items = list(set(unique_items))  \n",
    "    if '<padding>' not in unique_items:\n",
    "        unique_items.append('<padding>')\n",
    "    \n",
    "    mappings = {item: number for number, item in enumerate(unique_items)}\n",
    "    \n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(mappings, file)\n",
    "    return mappings\n",
    "\n",
    "def convert_to_int(items, mapping_file):\n",
    "    int_notes = []\n",
    "    with open(mapping_file, \"r\") as fp:\n",
    "        mappings = json.load(fp)\n",
    "    for item in items:\n",
    "        # if isinstance(item, list):\n",
    "        #     item_str = (str(item)\n",
    "        # else:\n",
    "        #     item_str = item\n",
    "        item_str = str(item)\n",
    "        int_notes.append(mappings.get(item_str, -1))\n",
    "    return int_notes\n",
    "\n",
    "def convert_notes_durations_to_int(items, note_mapping_path, duration_mapping):\n",
    "    encoded_notes = []\n",
    "    encoded_durations = []\n",
    "    with open(note_mapping_path, \"r\") as fp:\n",
    "        notes_mapping = json.load(fp)\n",
    "        \n",
    "    for item in items:\n",
    "        note, duration = item\n",
    "        encoded_durations.append(duration)\n",
    "    \n",
    "        encoded_note = notes_mapping.get(str(note), -1)\n",
    "        encoded_notes.append(encoded_note)\n",
    "    return encoded_notes, encoded_durations\n",
    "# def convert_to_int(items, mapping_file):\n",
    "#     int_items = []\n",
    "#     with open(mapping_file, \"r\") as fp:\n",
    "#         mappings = json.load(fp)\n",
    "#     for item in items:\n",
    "#         if isinstance(item, tuple):\n",
    "#             note, duration = item\n",
    "#             if isinstance(note, list):\n",
    "#                 note_str = '_'.join(str(i) for i in note)\n",
    "#             else:\n",
    "#                 note_str = str(note)\n",
    "#             int_note = mappings.get(note_str, -1)\n",
    "#             int_items.append((int_note, duration))\n",
    "#         else:\n",
    "#             int_items.append(mappings.get(str(item), -1))\n",
    "#     return int_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edb90d8b-b2f4-4de4-aff9-edd929198c33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "Error processing file: dataset/pop_909/513.mid\n",
      "Error message: 131778635447408\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "Error processing file: dataset/pop_909/320.mid\n",
      "Error message: 131778649523104\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "Error processing file: dataset/pop_909/102.mid\n",
      "Error message: 131778492465104\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "Error processing file: dataset/pop_909/437.mid\n",
      "Error message: 131778645758544\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "Error processing file: dataset/pop_909/850.mid\n",
      "Error message: 131778634480368\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "Error processing file: dataset/pop_909/503.mid\n",
      "Error message: 131778650694128\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "Error processing file: dataset/pop_909/072.mid\n",
      "Error message: 131778639812928\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "Error processing file: dataset/pop_909/372.mid\n",
      "Error message: 131778450017968\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "Error processing file: dataset/pop_909/077.mid\n",
      "Error message: 131778558006848\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "Error processing file: dataset/pop_909/740.mid\n",
      "Error message: 131778508769408\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "Error processing file: dataset/pop_909/512.mid\n",
      "Error message: 131778643754432\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "Error processing file: dataset/pop_909/895.mid\n",
      "Error message: 131778609729488\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "Error processing file: dataset/pop_909/647.mid\n",
      "Error message: 131778506355328\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "Error processing file: dataset/pop_909/701.mid\n",
      "Error message: 131778432865136\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "Error processing file: dataset/pop_909/071.mid\n",
      "Error message: 131778582535952\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "Error processing file: dataset/pop_909/563.mid\n",
      "Error message: 131778419858304\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "Error processing file: dataset/pop_909/691.mid\n",
      "Error message: 131778422366848\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "Error processing file: dataset/pop_909/524.mid\n",
      "Error message: 131778530425248\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "Error processing file: dataset/pop_909/500.mid\n",
      "Error message: 131778431115952\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "Error processing file: dataset/pop_909/519.mid\n",
      "Error message: 131778512419760\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "Error processing file: dataset/pop_909/048.mid\n",
      "Error message: 131778412176240\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "Error processing file: dataset/pop_909/879.mid\n",
      "Error message: 131778588986864\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "Error processing file: dataset/pop_909/509.mid\n",
      "Error message: 131778391390768\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "Error processing file: dataset/pop_909/408.mid\n",
      "Error message: 131776481873248\n",
      "Skipping file: dataset/pop_909/*.mid due to extraction error.\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n"
     ]
    }
   ],
   "source": [
    "midi_files = glob.glob(file_path)\n",
    "print(len(midi_files))\n",
    "# midi_files = midi_files[:10]\n",
    "all_files_chords = []\n",
    "all_files_notes = []\n",
    "all_files_durations = []\n",
    "count = 0\n",
    "for file in midi_files:\n",
    "    all_notes, all_durations, all_chords = extract_parts(file)\n",
    "    if all_notes is not None and all_chords is not None and all_durations is not None:\n",
    "        all_files_chords.extend(all_chords)\n",
    "        all_files_notes.extend(all_notes)\n",
    "        all_files_durations.extend(all_durations)\n",
    "        count += 1\n",
    "        print(count)\n",
    "    else:\n",
    "        print(f\"Skipping file: {file_path} due to extraction error.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4ffc06d-f5d8-4b7e-8b41-c4f8c9a5c404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992890 992890 992890\n",
      "[['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['vi6'], ['vi6']]\n"
     ]
    }
   ],
   "source": [
    "with open('mappings_model/all_chords.pkl', 'rb') as file:\n",
    "    all_files_chords = pickle.load(file)\n",
    "with open('mappings_model/all_durations.pkl', 'rb') as file:\n",
    "    all_files_durations = pickle.load(file)\n",
    "with open('mappings_model/all_notes.pkl', 'rb') as file:\n",
    "    all_files_notes = pickle.load(file)\n",
    "    \n",
    "print(len(all_files_chords), len(all_files_notes), len(all_files_durations))\n",
    "print(all_files_chords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a87384-c23f-4649-86f4-a9d4cb5ac193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "note_mapping_path = \"mappings_model/note_mappings.txt\"\n",
    "chord_mapping_path = \"mappings_model/chord_mappings.txt\"\n",
    "\n",
    "note_mapping = create_mappings(all_files_notes, note_mapping_path)\n",
    "chord_mapping = create_mappings(all_files_chords, chord_mapping_path)\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b780812-d1bb-4f61-a11d-46299454c08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['R'], ['R'], ['R'], ['R'], ['R'], ['R'], ['R'], ['R'], ['R'], ['R']]\n",
      "[['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['rest_or_no_chord'], ['vi6'], ['vi6']]\n",
      "[[3], [3], [3], [3], [3], [3], [3], [3], [3], [3]]\n"
     ]
    }
   ],
   "source": [
    "print(all_files_notes[:10])\n",
    "print(all_files_chords[:10])\n",
    "print(all_files_durations[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "821381c1-26a9-4326-8624-f301d3ddb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_notes = [tuple_element for sublist in all_files_notes for tuple_element in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b34dbc0a-1b48-490b-813b-9146c2d548c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992890 992890\n",
      "[403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 403, 68]\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 0]\n",
      "[447, 447, 447, 447, 447, 447, 447, 447, 613, 613, 613, 613, 410, 410, 410, 410, 410, 410, 410, 410]\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 64\n",
    "network_input_notes, network_input_durations, network_input_chords, network_output_notes, network_output_durations, network_output_chords, n_vocab_notes, n_vocab_chords, n_vocab_durations = preprocess_sequences(all_files_notes, all_files_durations, all_files_chords, sequence_length, note_mapping, chord_mapping_path, duration_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ee87af-e3d9-4848-8d38-e024576b6fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network input: [[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0\n",
      "  0 0 0 0 0 0 1 3 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0\n",
      "  0 0 0 0 0 1 3 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0 0\n",
      "  0 0 0 0 1 3 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0 0 0\n",
      "  0 0 0 1 3 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0\n",
      "  0 0 1 3 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0\n",
      "  0 1 3 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0\n",
      "  1 3 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3 2]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 1\n",
      "  3 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3 2 0]\n",
      " [3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 1 3\n",
      "  2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3 2 0 0]\n",
      " [3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 1 3 2\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3 2 0 0 0]], Network_output: [0 0 0 0 3 2 0 0 0 0],  Length: 690\n"
     ]
    }
   ],
   "source": [
    "print(f'Network input: {network_input_durations[:10]}, Network_output: {network_output_durations[:10]},  Length: {n_vocab_chords}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95ac9458-e69e-4cad-9acb-98cfa91ffac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992826 992826 992826\n"
     ]
    }
   ],
   "source": [
    "print(len(network_input_notes), len(network_input_durations), len(network_input_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb803fc0-6e16-4de8-b477-83d9a003f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mappings_model/all_chords.pkl', 'wb') as file:\n",
    "    pickle.dump(all_files_chords, file)\n",
    "with open('mappings_model/all_notes.pkl', 'wb') as file:\n",
    "    pickle.dump(all_files_notes, file)\n",
    "with open('mappings_model/all_durations.pkl', 'wb') as file:\n",
    "    pickle.dump(all_files_durations, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "279485d5-4e69-497c-b76d-3a17b2a82f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hierarchical_lstm_model(sequence_length, n_vocab_notes, n_vocab_chords, n_vocab_durations, note_embedding_dim, chord_embedding_dim, duration_embedding_dim, lstm_units, dropout_rate, learning_rate):\n",
    "    note_input = Input(shape=(sequence_length,), name='note_input')\n",
    "    note_embedding = Embedding(input_dim=n_vocab_notes + 1, output_dim=note_embedding_dim, input_length=sequence_length, name='note_embedding')(note_input)\n",
    "\n",
    "    duration_input = Input(shape=(sequence_length,), name='duration_input')\n",
    "    duration_embedding = Embedding(input_dim=n_vocab_durations + 1, output_dim=duration_embedding_dim, input_length=sequence_length, name='duration_embedding')(duration_input)\n",
    "    note_duration_embedding = Concatenate(name='note_duration_concat')([note_embedding, duration_embedding])\n",
    "    note_lstm = LSTM(lstm_units, return_sequences=True, name='note_lstm')(note_duration_embedding)\n",
    "    note_lstm_dropout = Dropout(dropout_rate, name='note_dropout')(note_lstm)\n",
    "\n",
    "    chord_input = Input(shape=(sequence_length,), name='chord_input')\n",
    "    chord_embedding = Embedding(input_dim=n_vocab_chords + 1, output_dim=chord_embedding_dim, input_length=sequence_length, name='chord_embedding')(chord_input)\n",
    "    chord_lstm = LSTM(lstm_units, return_sequences=True, name='chord_lstm')(chord_embedding)\n",
    "    chord_lstm_dropout = Dropout(dropout_rate, name='chord_dropout')(chord_lstm)\n",
    "\n",
    "    combined = Concatenate(name='concatenate')([note_lstm_dropout, chord_lstm_dropout])\n",
    "    combined_lstm = Bidirectional(LSTM(lstm_units, name='combined_lstm'))(combined)\n",
    "    combined_dropout = Dropout(dropout_rate, name='combined_dropout')(combined_lstm)\n",
    "\n",
    "    chord_output = Dense(n_vocab_chords + 1, activation='softmax', name='chord_output')(combined_dropout)\n",
    "    note_output = Dense(n_vocab_notes + 1, activation='softmax', name='note_output')(combined_dropout)\n",
    "    duration_output = Dense(n_vocab_durations + 1, activation='softmax', name='duration_output')(combined_dropout)\n",
    "\n",
    "    # Model compilation\n",
    "    model = Model(inputs=[note_input, duration_input, chord_input], outputs=[note_output, duration_output, chord_output])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0),\n",
    "                  loss={'note_output': 'sparse_categorical_crossentropy',\n",
    "                        'duration_output': 'sparse_categorical_crossentropy',\n",
    "                        'chord_output': 'sparse_categorical_crossentropy'\n",
    "                        },\n",
    "                  loss_weights={'note_output': 1.0, 'duration_output': 1.0, 'chord_output': 1.0, })\n",
    "\n",
    "    return model\n",
    "# def hierarchical_lstm_model_with_attention(sequence_length, n_vocab_notes, n_vocab_chords, note_embedding_dim, chord_embedding_dim, lstm_units, dropout_rate, learning_rate):\n",
    "#     note_input = Input(shape=(sequence_length,), name='note_input')\n",
    "#     note_embedding = Embedding(input_dim=n_vocab_notes + 1, output_dim=note_embedding_dim, input_length=sequence_length, name='note_embedding')(note_input)\n",
    "#     note_lstm = LSTM(lstm_units, return_sequences=True, name='note_lstm')(note_embedding)\n",
    "#     note_lstm_dropout = Dropout(dropout_rate, name='note_dropout')(note_lstm)\n",
    "\n",
    "#     chord_input = Input(shape=(sequence_length,), name='chord_input')\n",
    "#     chord_embedding = Embedding(input_dim=n_vocab_chords + 1, output_dim=chord_embedding_dim, input_length=sequence_length, name='chord_embedding')(chord_input)\n",
    "#     chord_lstm = LSTM(lstm_units, return_sequences=True, name='chord_lstm')(chord_embedding)\n",
    "#     chord_lstm_dropout = Dropout(dropout_rate, name='chord_dropout')(chord_lstm)\n",
    "\n",
    "#     combined = Concatenate(name='concatenate')([note_lstm_dropout, chord_lstm_dropout])\n",
    "#     combined_lstm = Bidirectional(LSTM(lstm_units // 2, return_sequences=True, name='combined_lstm'))(combined)\n",
    "#     # attention = Attention(name='attention')([combined_lstm, combined_lstm])\n",
    "    \n",
    "#     combined_dropout = Dropout(dropout_rate, name='combined_dropout')(combined_lstm)\n",
    "\n",
    "#     chord_output = Dense(n_vocab_chords + 1, activation='softmax', name='chord_output')(combined_dropout)\n",
    "#     note_output = Dense(n_vocab_notes + 1, activation='softmax', name='note_output')(combined_dropout)\n",
    "\n",
    "#     model = Model(inputs=[note_input, chord_input], outputs=[note_output, chord_output])\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss={'note_output': 'sparse_categorical_crossentropy', 'chord_output': 'sparse_categorical_crossentropy'}, loss_weights={'note_output': 1.0, 'chord_output': 1.0})\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22fec2be-1c41-46bc-951f-4eaae27d6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "learning_rate = 0.0005\n",
    "sequence_length = 64\n",
    "note_embedding_dim = 300\n",
    "chord_embedding_dim = 100\n",
    "duration_embedding_dim = 50\n",
    "lstm_units = 512\n",
    "dropout_rate = 0.4\n",
    "MODEL_PATH = \"mappings_model/model1.h5\"\n",
    "output_path = \"mappings_model/output1.mid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcd1b806-b285-4a2e-a4db-9d4f9e85e2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values found in network_input_notes.\n",
      "No NaN values found in network_input_chords.\n",
      "No NaN values found in network_input_durations.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in network_input_notes\n",
    "if np.isnan(network_output_notes).any():\n",
    "    print(\"NaN values found in network_input_notes!\")\n",
    "else:\n",
    "    print(\"No NaN values found in network_input_notes.\")\n",
    "\n",
    "# Check for NaN values in network_input_chords\n",
    "if np.isnan(network_output_chords).any():\n",
    "    print(\"NaN values found in network_input_chords!\")\n",
    "else:\n",
    "    print(\"No NaN values found in network_input_chords.\")\n",
    "\n",
    "# Check for NaN values in network_input_durations\n",
    "if np.isnan(network_output_durations).any():\n",
    "    print(\"NaN values found in network_input_durations!\")\n",
    "else:\n",
    "    print(\"No NaN values found in network_input_durations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e0a5947-e2b4-4081-9c24-096b5ee455e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 12:49:45.659433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 12:49:45.660152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-01 12:49:45.660240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-01 12:49:45.660283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-01 12:49:45.915492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-01 12:49:45.915583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-01 12:49:45.915626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-01 12:49:45.915671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10030 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:06:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 12:49:49.330525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3/7757 [..............................] - ETA: 4:23 - loss: 33.8467 - note_output_loss: 24.1851 - duration_output_loss: 1.2486 - chord_output_loss: 8.4130    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 12:49:49.670975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7757/7757 [==============================] - 261s 33ms/step - loss: 2.9006 - note_output_loss: 1.4220 - duration_output_loss: 0.5501 - chord_output_loss: 0.9285\n",
      "Epoch 2/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 2.0765 - note_output_loss: 0.9240 - duration_output_loss: 0.4671 - chord_output_loss: 0.6854\n",
      "Epoch 3/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.9226 - note_output_loss: 0.8438 - duration_output_loss: 0.4430 - chord_output_loss: 0.6358\n",
      "Epoch 4/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.8245 - note_output_loss: 0.7931 - duration_output_loss: 0.4259 - chord_output_loss: 0.6056\n",
      "Epoch 5/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.7470 - note_output_loss: 0.7529 - duration_output_loss: 0.4107 - chord_output_loss: 0.5834\n",
      "Epoch 6/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.6807 - note_output_loss: 0.7190 - duration_output_loss: 0.3963 - chord_output_loss: 0.5653\n",
      "Epoch 7/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.6214 - note_output_loss: 0.6885 - duration_output_loss: 0.3829 - chord_output_loss: 0.5500\n",
      "Epoch 8/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.5662 - note_output_loss: 0.6600 - duration_output_loss: 0.3700 - chord_output_loss: 0.5362\n",
      "Epoch 9/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.5162 - note_output_loss: 0.6357 - duration_output_loss: 0.3581 - chord_output_loss: 0.5224\n",
      "Epoch 10/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.4688 - note_output_loss: 0.6121 - duration_output_loss: 0.3463 - chord_output_loss: 0.5104\n",
      "Epoch 11/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.4233 - note_output_loss: 0.5899 - duration_output_loss: 0.3353 - chord_output_loss: 0.4981\n",
      "Epoch 12/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.3836 - note_output_loss: 0.5702 - duration_output_loss: 0.3264 - chord_output_loss: 0.4869\n",
      "Epoch 13/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.3437 - note_output_loss: 0.5513 - duration_output_loss: 0.3167 - chord_output_loss: 0.4757\n",
      "Epoch 14/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.3065 - note_output_loss: 0.5336 - duration_output_loss: 0.3079 - chord_output_loss: 0.4650\n",
      "Epoch 15/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.2737 - note_output_loss: 0.5183 - duration_output_loss: 0.3001 - chord_output_loss: 0.4553\n",
      "Epoch 16/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.2414 - note_output_loss: 0.5029 - duration_output_loss: 0.2924 - chord_output_loss: 0.4461\n",
      "Epoch 17/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.2100 - note_output_loss: 0.4885 - duration_output_loss: 0.2850 - chord_output_loss: 0.4365\n",
      "Epoch 18/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.1804 - note_output_loss: 0.4752 - duration_output_loss: 0.2786 - chord_output_loss: 0.4267\n",
      "Epoch 19/30\n",
      "7757/7757 [==============================] - 260s 33ms/step - loss: 1.1553 - note_output_loss: 0.4636 - duration_output_loss: 0.2727 - chord_output_loss: 0.4189\n",
      "Epoch 20/30\n",
      "7757/7757 [==============================] - 260s 33ms/step - loss: 1.1282 - note_output_loss: 0.4513 - duration_output_loss: 0.2668 - chord_output_loss: 0.4100\n",
      "Epoch 21/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.1028 - note_output_loss: 0.4404 - duration_output_loss: 0.2608 - chord_output_loss: 0.4016\n",
      "Epoch 22/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.0802 - note_output_loss: 0.4296 - duration_output_loss: 0.2563 - chord_output_loss: 0.3943\n",
      "Epoch 23/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.0584 - note_output_loss: 0.4202 - duration_output_loss: 0.2514 - chord_output_loss: 0.3867\n",
      "Epoch 24/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.0356 - note_output_loss: 0.4098 - duration_output_loss: 0.2462 - chord_output_loss: 0.3796\n",
      "Epoch 25/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 1.0164 - note_output_loss: 0.4017 - duration_output_loss: 0.2425 - chord_output_loss: 0.3723\n",
      "Epoch 26/30\n",
      "7757/7757 [==============================] - 260s 33ms/step - loss: 0.9952 - note_output_loss: 0.3928 - duration_output_loss: 0.2377 - chord_output_loss: 0.3647\n",
      "Epoch 27/30\n",
      "7757/7757 [==============================] - 259s 33ms/step - loss: 0.9778 - note_output_loss: 0.3849 - duration_output_loss: 0.2341 - chord_output_loss: 0.3588\n",
      "Epoch 28/30\n",
      "7757/7757 [==============================] - 260s 33ms/step - loss: 0.9598 - note_output_loss: 0.3766 - duration_output_loss: 0.2301 - chord_output_loss: 0.3531\n",
      "Epoch 29/30\n",
      "7757/7757 [==============================] - 260s 33ms/step - loss: 0.9424 - note_output_loss: 0.3700 - duration_output_loss: 0.2267 - chord_output_loss: 0.3457\n",
      "Epoch 30/30\n",
      "7757/7757 [==============================] - 260s 33ms/step - loss: 0.9248 - note_output_loss: 0.3631 - duration_output_loss: 0.2226 - chord_output_loss: 0.3391\n"
     ]
    }
   ],
   "source": [
    "def train(continue_training=False):\n",
    "    network_input = [network_input_notes, network_input_durations, network_input_chords]\n",
    "    network_output = [network_output_notes, network_output_durations, network_output_chords]\n",
    "    \n",
    "    if continue_training:\n",
    "        # Load the previously trained model\n",
    "        model = load_model(MODEL_PATH)\n",
    "    else:\n",
    "        # Create a new model\n",
    "        model = hierarchical_lstm_model(sequence_length, n_vocab_notes, n_vocab_chords, n_vocab_durations, note_embedding_dim, chord_embedding_dim, duration_embedding_dim, lstm_units, dropout_rate, learning_rate)\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  # Monitor the validation loss\n",
    "        patience=10,  # Number of epochs to wait for improvement\n",
    "        verbose=1,  # Print messages when early stopping is triggered\n",
    "        mode='min'  # Look for a minimum value of the monitored metric\n",
    "    )\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0),\n",
    "                  loss={'note_output': 'sparse_categorical_crossentropy',\n",
    "                        'duration_output': 'sparse_categorical_crossentropy',\n",
    "                        'chord_output': 'sparse_categorical_crossentropy'},\n",
    "                  loss_weights={'note_output': 1.0, 'chord_output': 1.0, 'duration_output': 1.0})\n",
    "\n",
    "\n",
    "    model.fit(network_input, network_output,\n",
    "              epochs=EPOCHS,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              callbacks=[early_stopping])\n",
    "    \n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "\n",
    "train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63049b1e-655e-40fa-abe5-cd79037d20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def temperature_sampling(predictions, temperature=1.0):\n",
    "    scaled = np.log(predictions) / temperature\n",
    "    probabilities = softmax(scaled)\n",
    "    choice = np.random.choice(len(probabilities), p=probabilities) # choose according to probability\n",
    "    return choice\n",
    "    \n",
    "def predict_notes(model_path, starting_notes, starting_durations, starting_chords, sequence_length, n_notes=300, temperature=1.0):\n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    prediction_output_notes = []  \n",
    "    prediction_output_durations = []\n",
    "    \n",
    "    starting_chords_int = convert_to_int(starting_chords, chord_mapping_path)\n",
    "    # starting_notes_int, starting_durations_int = convert_notes_durations_to_int(starting_notes, note_mapping_path, duration_mapping)\n",
    "    starting_notes_int = convert_to_int(starting_notes, note_mapping_path)\n",
    "    starting_durations_int = [duration[0] for duration in starting_durations]\n",
    "    \n",
    "    with open(note_mapping_path, \"r\") as fp:\n",
    "        note_mappings = json.load(fp)\n",
    "        \n",
    "    reverse_note_mappings = {value: key for key, value in note_mappings.items()}\n",
    "    reverse_duration_mappings = {value: key for key, value in duration_mapping.items()}\n",
    "\n",
    "    prediction_output_notes.extend([reverse_note_mappings[note] for note in starting_notes_int])\n",
    "    prediction_output_durations.extend(reverse_duration_mappings[duration] for duration in starting_durations_int)\n",
    "    \n",
    "    for _ in range(n_notes):\n",
    "        input_sequence_chords = np.array(starting_chords_int[-sequence_length:]).reshape(1, sequence_length)\n",
    "        input_sequence_notes = np.array(starting_notes_int[-sequence_length:]).reshape(1, sequence_length)\n",
    "        input_sequence_durations = np.array(starting_durations_int[-sequence_length:]).reshape(1, sequence_length)\n",
    "\n",
    "        prediction_notes, prediction_durations, prediction_chords = model.predict([input_sequence_notes, input_sequence_durations, input_sequence_chords], verbose=0)\n",
    "        next_note = temperature_sampling(prediction_notes[0], temperature)  \n",
    "        next_duration = temperature_sampling(prediction_durations[0], temperature)  \n",
    "        next_chord = temperature_sampling(prediction_chords[0], temperature) \n",
    "        \n",
    "        starting_notes_int.append(next_note)\n",
    "        starting_durations_int.append(next_duration)\n",
    "        starting_chords_int.append(next_chord)\n",
    "        \n",
    "        prediction_output_notes.append(reverse_note_mappings[next_note])\n",
    "        prediction_output_durations.append(reverse_duration_mappings[next_duration])\n",
    "    print(starting_chords_int)\n",
    "    # res.extend(prediction_output_notes)\n",
    "\n",
    "    return prediction_output_notes, prediction_output_durations, starting_chords_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564eae20-9150-42f5-819b-a1114eb1c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_notes = all_files_notes[1400:1464]\n",
    "starting_chords = all_files_chords[1400:1464]\n",
    "starting_durations = all_files_durations[1400:1464]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b9e0aeb-6f65-4955-8f7e-99afa58c5a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9], [0], [1], [0], [0], [0], [1], [1], [0], [1], [1], [0], [0], [6], [2], [9], [0], [1], [0], [0], [0], [1], [1], [0], [3], [6], [0], [1], [1], [0], [1], [1], [0], [3], [2], [0], [14], [0], [1], [9], [0], [1], [0], [0], [0], [0], [0], [2], [1], [1], [0], [0], [2], [0], [1], [0], [0], [0], [1], [9], [0], [1], [0], [0]]\n"
     ]
    }
   ],
   "source": [
    "print(starting_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d25cc2bd-823f-4ebd-8e2a-ac677e6fa1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39, 39, 574, 574, 574, 574, 609, 609, 609, 609, 429, 429, 429, 429, 39, 39, 39, 39, 574, 574, 574, 574, 377, 377, 377, 377, 58, 58, 58, 58, 270, 270, 270, 270, 325, 325, 325, 325, 23, 23, 23, 23, 285, 285, 285, 285, 148, 148, 148, 148, 447, 447, 447, 447, 377, 377, 377, 377, 58, 58, 58, 58, 447, 447, 447, 447, 368, 368, 368, 368, 285, 285, 285, 285, 429, 429, 429, 429, 148, 148, 148, 148, 429, 429, 429, 429, 574, 574, 574, 574, 447, 447, 447, 447, 447, 447, 447, 447, 285, 285, 285, 285, 57, 57, 57, 57, 54, 54, 54, 54, 148, 148, 148, 148, 418, 418, 418, 418, 410, 410, 410, 410, 643, 643, 643, 643, 57, 57, 57, 57, 447, 447, 447, 447, 285, 285, 285, 285, 447, 447, 447, 447, 23, 23, 23, 23, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 58, 58, 58, 58, 447, 447, 447, 447, 147, 147, 147, 147, 447, 447, 447, 447, 39, 39, 39, 39, 368, 368, 368, 368, 325, 325, 325, 325, 447, 447, 447, 447, 377, 377, 377, 377, 447, 447, 447, 447, 175, 175, 175, 175, 447, 447, 447, 447, 175, 175, 175, 175, 429, 429, 429, 429, 58, 58, 58, 58, 447, 447, 447, 447, 429, 429, 429, 429, 447, 447, 447, 447, 412, 412, 412, 412, 447, 447, 447, 447, 39, 39, 39, 39, 147, 147, 147, 147, 377, 377, 377, 377, 447, 447, 447, 447, 333, 333, 333, 333, 278, 278, 278, 278, 447, 447, 447, 447, 447, 447, 447, 447, 57, 57, 57, 57, 217, 217, 217, 217, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 410, 410, 410, 410, 175, 175, 175, 175, 447, 447, 447, 447, 39, 39, 39, 39, 447, 447, 447, 447, 327, 327, 327, 327, 447, 447, 447, 447, 447, 447, 447, 447, 46, 46, 46, 46, 57, 57, 57, 57, 447, 447, 447, 447, 327, 327, 327, 327, 536, 536, 536, 536, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 447, 410, 410, 410, 410, 447, 447, 447, 447, 447, 447, 447, 447, 401, 401, 401, 401, 447, 447, 447, 447, 447, 447, 447, 447, 643, 643, 643, 643, 57, 57, 57, 57, 447, 447, 447, 447, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 629, 447, 447, 447, 447, 175, 175, 175, 175, 666, 666, 666, 666, 401, 401, 401, 401, 447, 447, 447, 447, 372]\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 64\n",
    "n_notes = 400\n",
    "prediction_output_notes, prediction_output_durations, predicted_chords = predict_notes(MODEL_PATH, starting_notes, starting_durations, starting_chords, sequence_length, n_notes, temperature=1.18)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "028eda39-fdee-4773-86fd-70209fa6afc0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e524614f-245d-48e2-ac36-5864151eb8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 464 464\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction_output_notes), len(prediction_output_durations), len(predicted_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e89a4a8-c6fd-444e-ba45-4e65f9a16823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71], ['R'], [71], [71], [71], ['R'], [76], [76], ['R'], [74], [74], ['R'], [71], [74], [74], [79], ['R'], [79], [79], [79]]\n"
     ]
    }
   ],
   "source": [
    "print(starting_notes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91baf8d2-6057-408e-899e-157abcbd7fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[71]', \"['R']\", '[71]', '[71]', '[71]', \"['R']\", '[76]', '[76]', \"['R']\", '[74]', '[74]', \"['R']\", '[71]', '[74]', '[74]', '[79]', \"['R']\", '[79]', '[79]', '[79]', \"['R']\", '[79]', '[76]', \"['R']\", '[74]', '[71]', '[71]', '[71]', '[71]', \"['R']\", '[69]', '[69]', \"['R']\", '[69]', '[67]', '[67]', '[69]', '[69]', '[62]', '[71]', \"['R']\", '[71]', '[72]', '[72]', \"['R']\", '[74]', '[74]', \"['R']\", '[72]', '[72]', \"['R']\", '[71]', '[71]', \"['R']\", '[69]', '[69]', '[69]', \"['R']\", '[67]', '[71]', \"['R']\", '[71]', '[71]', '[71]', \"['R']\", '[72]', '[74]', \"['R']\", '[72]', '[74]', \"['R']\", '[76]', '[76]', '[69]', '[69]', '[67]', \"['R']\", '[79]', '[79]', \"['R']\", '[76]', '[74]', \"['R']\", '[74]', '[74]', \"['R']\", '[72]', '[69]', '[69]', '[69]', '[69]', '[71]', '[67]', \"['R']\", '[69]', '[71]', \"['R']\", '[71]', '[71]', '[71]', \"['R']\", '[71]', '[69]', \"['R']\", '[69]', '[67]', \"['R']\", '[69]', '[69]', '[69]', '[67]', \"['R']\", '[72]', '[74]', \"['R']\", '[74]', '[74]', '[74]', \"['R']\", '[72]', '[74]', \"['R']\", '[74]', '[74]', '[74]', \"['R']\", '[74]', '[69]', '[67]', '[67]', '[74]', '[74]', '[62]', '[64]', \"['R']\", '[69]', '[69]', '[67]', '[67]', \"['R']\", '[69]', '[67]', '[67]', '[67]', '[67]', '[69]', '[67]', '[67]', '[69]', \"['R']\", '[69]', '[69]', '[67]', '[64]', '[64]', '[64]', '[64]', '[62]', '[60]', '[60]', '[74]', \"['R']\", '[71]', '[67]', '[67]', '[67]', '[67]', '[69]', '[69]', '[69]', '[72]', \"['R']\", '[72]', '[72]', '[72]', \"['R']\", '[69]', '[67]', \"['R']\", '[69]', '[69]', '[69]', \"['R']\", '[69]', '[67]', '[62]', '[62]', \"['R']\", '[65]', '[67]', \"['R']\", '[67]', '[62]', \"['R']\", '[67]', '[67]', \"['R']\", '[67]', '[69]', '[69]', '[67]', \"['R']\", '[77]', \"['R']\", '[77]', '[74]', \"['R']\", '[72]', '[69]', \"['R']\", '[69]', '[67]', '[70]', '[69]', '[67]', '[67]', '[62]', \"['R']\", '[64]', '[65]', '[69]', '[69]', \"['R']\", '[62]', '[64]', \"['R']\", '[62]', '[62]', \"['R']\", '[62]', '[62]', '[60]', '[67]', \"['R']\", '[66]', '[67]', \"['R']\", '[65]', '[62]', '[67]', '[69]', '[69]', '[72]', '[77]', '[77]', \"['R']\", '[79]', '[81]', \"['R']\", '[81]', '[79]', \"['R']\", '[77]', '[74]', '[74]', '[77]', '[72]', \"['R']\", '[74]', '[72]', '[69]', '[72]', '[72]', '[67]', '[74]', '[74]', '[69]', '[69]', '[67]', \"['R']\", '[67]', '[69]', '[69]', '[72]', '[72]', '[72]', \"['R']\", '[74]', '[74]', '[74]', '[74]', '[74]', '[74]', \"['R']\", '[72]', '[72]', '[74]', '[74]', \"['R']\", '[67]', '[69]', \"['R']\", '[69]', '[72]', \"['R']\", '[72]', '[74]', '[74]', \"['R']\", '[72]', '[72]', '[72]', '[72]', '[72]', '[69]', \"['R']\", '[69]', '[72]', '[72]', \"['R']\", '[72]', '[74]', '[76]', '[76]', '[76]', '[76]', \"['R']\", '[77]', '[77]', '[79]', '[79]', '[81]', '[84]', '[84]', \"['R']\", '[81]', '[77]', '[77]', '[72]', \"['R']\", '[84]', '[84]', '[82]', '[81]', '[79]', '[77]', '[77]', '[77]', \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", '[81]', '[81]', '[79]', '[81]', '[81]', '[79]', \"['R']\", '[79]', '[81]', '[81]', '[79]', '[77]', '[79]', '[81]', '[81]', \"['R']\", '[72]', '[74]', '[77]', '[79]', '[81]', '[86]', '[83]', '[81]', \"['R']\", '[67]', '[72]', \"['R']\", '[72]', '[74]', \"['R']\", '[79]', \"['R']\", '[72]', '[74]', '[72]', \"['R']\", '[74]', '[76]', '[79]', '[79]', '[79]', \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", '[69]', '[69]', \"['R']\", '[77]', '[77]', '[76]', '[74]', '[72]', '[72]', '[76]', \"['R']\", '[77]', '[74]', '[72]', '[72]', '[77]', '[79]', '[81]', '[76]', '[76]', \"['R']\", '[76]', '[74]', \"['R']\", \"['R']\", '[81]', '[81]', '[81]', '[79]', '[77]', '[74]', '[76]', \"['R']\", '[74]', '[74]', '[76]', '[79]', '[81]', '[79]', '[74]', \"['R']\", '<end>', \"['R']\", '[74]', '[69]', '[72]', '[72]', \"['R']\", '[72]', '[73]', '[74]', '[76]', \"['R']\", '<end>', \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\", \"['R']\"] [2.5, 0.25, 0.5, 0.25, 0.25, 0.25, 0.5, 0.5, 0.25, 0.5, 0.5, 0.25, 0.25, 1.75, 0.75, 2.5, 0.25, 0.5, 0.25, 0.25]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_output_notes, prediction_output_durations[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a040d0db-d3ac-45f9-bf62-71499a33f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(predicted_notes, predicted_durations, output_path=output_path):\n",
    "    s = stream.Stream()\n",
    "    for i, note_str in enumerate(predicted_notes):\n",
    "        if note_str == '<end>':\n",
    "            break\n",
    "        elif note_str == '<padding>':\n",
    "            continue\n",
    "        else:\n",
    "            note = eval(note_str)\n",
    "            if note == ['R']:\n",
    "                r = note_module.Rest()\n",
    "                r.quarterLength = int(predicted_durations[i])\n",
    "                s.append(r)\n",
    "\n",
    "            else:\n",
    "                n = note_module.Note()\n",
    "                if isinstance(note, list) and len(note) > 0 and isinstance(note[0], int):\n",
    "                    n.pitch.midi = note[0]\n",
    "                    n.quarterLength = float(predicted_durations[i])\n",
    "                    s.append(n)\n",
    "\n",
    "    s.write('midi', fp=output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "111f805b-6754-4374-ab43-0f3b1717abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_midi(prediction_output_notes, prediction_output_durations, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d23f74-0025-40a5-abbb-955373bbb650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
